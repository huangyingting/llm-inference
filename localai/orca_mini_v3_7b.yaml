name: "orca_mini_v3_7b"

description: |
  A LLama2-7b model trained on Orca Style datasets. 

license: "https://ai.meta.com/llama/license/"
urls:
- https://ai.meta.com/llama/

config_file: |
  name: orca_mini_v3_7b
  backend: llama
  context_size: 4096
  f16: true
  gpu_layers: 512
  debug: true
  low_vram: false
  parameters:
    model: orca_mini_v3_7b.ggmlv3.q8_0.bin
    f16: true
    temperature: 0.6
    top_p: 0.9
  context_size: 4096
  template:
    chat_message: orca_mini_v3_7b_chat
    completion: orca_mini_v3_7b_completion  
  system_prompt: |
    You are an AI assistant that follows instruction extremely well. Help as much as you can.

files:
    - filename: "orca_mini_v3_7b.ggmlv3.q8_0.bin"
      sha256: "0f0c17dcac15deab53d2b9252188adce8bf0b13cf2d6344aee30d0a03c8f97f7"
      uri: "https://huggingface.co/TheBloke/orca_mini_v3_7B-GGML/resolve/main/orca_mini_v3_7b.ggmlv3.q8_0.bin"

prompt_templates:
- name: "orca_mini_v3_7b_chat"
  content: |
    {{if eq .RoleName "assistant"}}{{.Content}}{{else}}
    [INST]
    {{if eq .RoleName "system"}}<<SYS>>{{.Content}}<</SYS>>{{else if and (.SystemPrompt) (eq .MessageIndex 0)}}<<SYS>>{{.SystemPrompt}}<</SYS>>{{end}}
    {{if .Content}}{{.Content}}{{end}}
    [/INST] 
    {{end}}

    ### Response:
- name: "orca_mini_v3_7b_completion"
  content: |
      Complete the following sentence: {{.Input}}